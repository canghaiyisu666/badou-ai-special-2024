{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a40f738-d0de-4107-a8e4-c510bbae6b21",
   "metadata": {},
   "source": [
    "### YOLOv1骨干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff830b5-1de9-4fe0-9e67-90c0b8549e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        super(YOLOv1, self).__init__()\n",
    "        self.S = S  # Grid size\n",
    "        self.B = B  # Number of bounding boxes\n",
    "        self.C = C  # Number of classes\n",
    "        \n",
    "        # 构建YOLOv1的卷积层和池化层\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),  # Conv 64, 7x7/2\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),  # Max Pool 2x2/2\n",
    "            \n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),  # Conv 192, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),  # Max Pool 2x2/2\n",
    "            \n",
    "            nn.Conv2d(192, 128, kernel_size=1, stride=1),  # Conv 128, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # Conv 256, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 256, kernel_size=1, stride=1),  # Conv 256, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # Conv 512, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),  # Max Pool 2x2/2\n",
    "            \n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1),  # Conv 256, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # Conv 512, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1),  # Conv 256, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # Conv 512, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 256, kernel_size=1, stride=1),  # Conv 256, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # Conv 512, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 512, kernel_size=1, stride=1),  # Conv 512, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),  # Max Pool 2x2/2\n",
    "            \n",
    "            nn.Conv2d(1024, 512, kernel_size=1, stride=1),  # Conv 512, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(1024, 512, kernel_size=1, stride=1),  # Conv 512, 1x1/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1),  # Conv 1024, 3x3/2\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),  # Conv 1024, 3x3/1\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * 7 * 7, 4096),  # FC1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, self.S * self.S * (self.C + self.B * 5))  # FC2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)  # 通过卷积层\n",
    "        x = self.fc_layers(x)  # 通过全连接层\n",
    "        x = x.view(-1, self.S, self.S, self.C + self.B * 5)  # 调整输出形状\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6bd3c-f6d3-4efe-af81-d753274ee941",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2cf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.S = S  # 网格大小\n",
    "        self.B = B  # 每个网格预测的边界框数量\n",
    "        self.C = C  # 类别数量\n",
    "        self.lambda_coord = lambda_coord  # 坐标损失权重\n",
    "        self.lambda_noobj = lambda_noobj  # 没有物体时置信度损失权重\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # 预测的形状: (batch_size, S*S*(B*5 + C))\n",
    "        predictions = predictions.view(-1, self.S, self.S, self.B * 5 + self.C)\n",
    "        target = target.view(-1, self.S, self.S, self.B * 5 + self.C)\n",
    "\n",
    "        # 分离预测的各个部分\n",
    "        pred_boxes = predictions[..., :self.B*5].view(-1, self.S, self.S, self.B, 5)\n",
    "        pred_classes = predictions[..., self.B*5:]  # (batch_size, S, S, C)\n",
    "\n",
    "        # 分离目标的各个部分\n",
    "        target_boxes = target[..., :5].view(-1, self.S, self.S, 5)\n",
    "        # 在第三个维度之后添加一个新的维度\n",
    "        target_boxes = target_boxes.unsqueeze(3)  # 新形状为 (batch_size, 7, 7, 1, 5)\n",
    "        # 第二步：将新添加的维度从大小1广播到大小2\n",
    "        target_boxes = target_boxes.expand(-1, -1, -1, 2, -1)  # 最终形状为 (batch_size, 7, 7, 2, 5)\n",
    "        target_classes = target[..., self.B*5:]  # (batch_size, S, S, C)\n",
    "        \n",
    "#         # 分离目标的各个部分\n",
    "#         target_boxes = target[..., :5].view(-1, self.S, self.S, self.B, 5)\n",
    "#         target_classes = target[..., self.B*5:]  # (batch_size, S, S, C)\n",
    "\n",
    "#         # 创建掩码\n",
    "#         # 对象掩码：标记哪个网格单元包含物体\n",
    "#         obj_mask = target_boxes[..., 4] > 0  # (batch_size, S, S, B)\n",
    "#         noobj_mask = target_boxes[..., 4] == 0  # (batch_size, S, S, B)\n",
    "        \n",
    "        # 创建掩码\n",
    "        # 对象掩码：标记哪个网格单元包含物体\n",
    "        obj_mask = target[..., 4] > 0  # (batch_size, S, S)\n",
    "        noobj_mask = target[..., 4] == 0  # (batch_size, S, S)\n",
    "        \n",
    "        # 将掩码扩展到边界框维度\n",
    "        obj_mask = obj_mask.unsqueeze(-1).expand(-1, -1, -1, self.B)  # (batch_size, S, S, B)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand(-1, -1, -1, self.B)  # (batch_size, S, S, B)\n",
    "        \n",
    "        # 计算IoU并找到负责预测的边界框\n",
    "        ious = self.calculate_iou(pred_boxes[..., :4], target_boxes[..., :4])  # (batch_size, S, S, B)\n",
    "        _, best_box = ious.max(dim=-1, keepdim=True)  # (batch_size, S, S, 1)\n",
    "        best_box = best_box.long()  # 确保数据类型为long\n",
    "\n",
    "        # 负责预测物体的边界框掩码\n",
    "        resp_mask = torch.zeros_like(obj_mask, dtype=torch.bool)  # (batch_size, S, S, B)\n",
    "        resp_mask.scatter_(-1, best_box, True)  # 将负责的边界框位置置为True\n",
    "\n",
    "        # 坐标损失\n",
    "        coord_loss = self.lambda_coord * self.coordinate_loss(pred_boxes, target_boxes, resp_mask)\n",
    "\n",
    "        # 置信度损失\n",
    "        conf_loss = self.confidence_loss(pred_boxes[..., 4], target_boxes[..., 4], obj_mask, noobj_mask, resp_mask)\n",
    "\n",
    "        # 类别损失\n",
    "        class_loss = self.class_loss(pred_classes, target_classes, obj_mask)\n",
    "\n",
    "        total_loss = coord_loss + conf_loss + class_loss\n",
    "        return total_loss\n",
    "\n",
    "    def coordinate_loss(self, pred_boxes, target_boxes, resp_mask):\n",
    "        # 只计算负责预测物体的边界框的坐标损失\n",
    "        pred_xy = pred_boxes[..., :2][resp_mask]\n",
    "        pred_wh = pred_boxes[..., 2:4][resp_mask]\n",
    "        pred_wh = torch.sign(pred_wh) * torch.sqrt(torch.abs(pred_wh) + 1e-6)  # 避免负值\n",
    "\n",
    "        target_xy = target_boxes[..., :2][resp_mask]\n",
    "        target_wh = target_boxes[..., 2:4][resp_mask]\n",
    "        target_wh = torch.sqrt(target_wh)\n",
    "\n",
    "        # 计算损失\n",
    "        xy_loss = nn.functional.mse_loss(pred_xy, target_xy, reduction='sum')\n",
    "        wh_loss = nn.functional.mse_loss(pred_wh, target_wh, reduction='sum')\n",
    "        coord_loss = xy_loss + wh_loss\n",
    "        return coord_loss\n",
    "\n",
    "    def confidence_loss(self, pred_conf, target_conf, obj_mask, noobj_mask, resp_mask):\n",
    "        # 负责预测物体的边界框的置信度损失\n",
    "        conf_loss_obj = nn.functional.mse_loss(pred_conf[resp_mask], target_conf[resp_mask], reduction='sum')\n",
    "\n",
    "        # 不负责预测物体的边界框的置信度损失，乘以lambda_noobj权重\n",
    "        conf_loss_noobj = nn.functional.mse_loss(pred_conf[noobj_mask], target_conf[noobj_mask], reduction='sum')\n",
    "        conf_loss_noobj = self.lambda_noobj * conf_loss_noobj\n",
    "\n",
    "        conf_loss = conf_loss_obj + conf_loss_noobj\n",
    "        return conf_loss\n",
    "\n",
    "    def class_loss(self, pred_classes, target_classes, obj_mask):\n",
    "        # 只在包含物体的网格单元计算类别损失\n",
    "        obj_mask = obj_mask.any(dim=-1)  # (batch_size, S, S)\n",
    "        pred_classes = pred_classes[obj_mask]\n",
    "        target_classes = target_classes[obj_mask]\n",
    "        class_loss = nn.functional.mse_loss(pred_classes, target_classes, reduction='sum')\n",
    "        return class_loss\n",
    "\n",
    "    def calculate_iou(self, pred_boxes, target_boxes):\n",
    "        # pred_boxes: (batch_size, S, S, B, 4)\n",
    "        # target_boxes: (batch_size, S, S, 1, 4)\n",
    "\n",
    "        # 添加目标边界框的维度以进行广播\n",
    "        target_boxes = target_boxes[..., 0, :].unsqueeze(-2)  # (batch_size, S, S, 1, 4)\n",
    "\n",
    "        # 预测边界框的坐标\n",
    "        pred_xy = pred_boxes[..., :2]\n",
    "        pred_wh = pred_boxes[..., 2:4] / 2\n",
    "        pred_min = pred_xy - pred_wh\n",
    "        pred_max = pred_xy + pred_wh\n",
    "\n",
    "        # 目标边界框的坐标\n",
    "        target_xy = target_boxes[..., :2]\n",
    "        target_wh = target_boxes[..., 2:4] / 2\n",
    "        target_min = target_xy - target_wh\n",
    "        target_max = target_xy + target_wh\n",
    "\n",
    "        # 计算交集\n",
    "        intersect_min = torch.max(pred_min, target_min)\n",
    "        intersect_max = torch.min(pred_max, target_max)\n",
    "        intersect_wh = torch.clamp(intersect_max - intersect_min, min=0)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "        # 计算并集\n",
    "        pred_area = (pred_max[..., 0] - pred_min[..., 0]) * (pred_max[..., 1] - pred_min[..., 1])\n",
    "        target_area = (target_max[..., 0] - target_min[..., 0]) * (target_max[..., 1] - target_min[..., 1])\n",
    "        union_area = pred_area + target_area - intersect_area\n",
    "\n",
    "        # 计算IoU\n",
    "        iou = intersect_area / (union_area + 1e-6)  # 避免除以零\n",
    "\n",
    "        # 返回形状为 (batch_size, S, S, B) 的IoU张量\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a916533-7bb3-414c-b1e9-725bc65effc4",
   "metadata": {},
   "source": [
    "### 处理PASCAL VOC 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a71cb-c7a9-411d-a02d-b201bfc1166b",
   "metadata": {},
   "source": [
    "需要下载数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69170b1-3323-4700-af6e-24693c513a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./data\\VOCtrainval_06-Nov-2007.tar to ./data\n",
      "torch.Size([16, 3, 448, 448])\n",
      "torch.Size([16, 7, 7, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "VOC_CLASSES = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "    'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
    "    'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
    "    'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, root, year='2007', image_set='train', S=7, B=2, C=20, transform=None, download=False):\n",
    "        self.S = S  # 网格大小\n",
    "        self.B = B  # 每个网格预测的边界框数量\n",
    "        self.C = C  # 类别数量\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 使用 torchvision 的 VOCDetection 自动下载并加载数据\n",
    "        self.voc_dataset = datasets.VOCDetection(root=root, year=year, image_set=image_set, download=download)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.voc_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图像和对应的目标（目标是 Pascal VOC 原始标签格式）\n",
    "        image, target = self.voc_dataset[idx]\n",
    "        \n",
    "        # 解析目标并转换为 YOLOv1 的格式\n",
    "        target = self.parse_voc_annotation(target)\n",
    "\n",
    "        # 应用图像预处理\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def parse_voc_annotation(self, target):\n",
    "        # 获取图像的宽度和高度\n",
    "        width = int(target['annotation']['size']['width'])\n",
    "        height = int(target['annotation']['size']['height'])\n",
    "\n",
    "        # 初始化 YOLO 格式的标签\n",
    "        yolo_target = torch.zeros((self.S, self.S, self.B * 5 + self.C))\n",
    "\n",
    "        for obj in target['annotation']['object']:\n",
    "            class_name = obj['name']\n",
    "            if class_name not in VOC_CLASSES:\n",
    "                continue\n",
    "            class_idx = VOC_CLASSES.index(class_name)\n",
    "\n",
    "            # 获取物体的边界框信息 (xmin, ymin, xmax, ymax)\n",
    "            bndbox = obj['bndbox']\n",
    "            xmin = float(bndbox['xmin']) / width\n",
    "            ymin = float(bndbox['ymin']) / height\n",
    "            xmax = float(bndbox['xmax']) / width\n",
    "            ymax = float(bndbox['ymax']) / height\n",
    "\n",
    "            # 计算中心点坐标和宽高\n",
    "            x_center = (xmin + xmax) / 2\n",
    "            y_center = (ymin + ymax) / 2\n",
    "            w = xmax - xmin\n",
    "            h = ymax - ymin\n",
    "\n",
    "            # 将中心点映射到 S x S 网格中\n",
    "            grid_x = int(x_center * self.S)\n",
    "            grid_y = int(y_center * self.S)\n",
    "\n",
    "            # 计算中心点相对于网格单元的偏移\n",
    "            x_offset = x_center * self.S - grid_x\n",
    "            y_offset = y_center * self.S - grid_y\n",
    "\n",
    "            # 设置标签，包括 (x, y, w, h, confidence) 和 one-hot 编码的类别\n",
    "            yolo_target[grid_y, grid_x, :5] = torch.tensor([x_offset, y_offset, w, h, 1])  # 置信度为1\n",
    "            yolo_target[grid_y, grid_x, 5 + class_idx] = 1  # 类别的 one-hot 编码\n",
    "\n",
    "        return yolo_target\n",
    "\n",
    "# 定义图像预处理步骤\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 创建数据集实例，自动下载并处理数据\n",
    "train_dataset = VOCDataset(\n",
    "    root='./data', \n",
    "    year='2007', \n",
    "    image_set='train', \n",
    "    S=7, \n",
    "    B=2, \n",
    "    C=20, \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 遍历数据集，打印示例\n",
    "for images, targets in train_loader:\n",
    "    print(images.shape)  # 输出图像的形状\n",
    "    print(targets.shape)\n",
    "    break  # 只打印一批数据的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf64fa-1489-4982-a4bd-46a65d9b3975",
   "metadata": {},
   "source": [
    "### 完整的训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb1cc0-e5da-40c8-a2ad-bfb5696e83cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [0/157], Loss: 393.3239\n",
      "Epoch [1/100], Step [10/157], Loss: 501.5385\n",
      "Epoch [1/100], Step [20/157], Loss: 413.3436\n",
      "Epoch [1/100], Step [30/157], Loss: 335.0783\n",
      "Epoch [1/100], Step [40/157], Loss: 227.4185\n",
      "Epoch [1/100], Step [50/157], Loss: 333.6342\n",
      "Epoch [1/100], Step [60/157], Loss: 464.4411\n",
      "Epoch [1/100], Step [70/157], Loss: 375.6880\n",
      "Epoch [1/100], Step [80/157], Loss: 421.6037\n",
      "Epoch [1/100], Step [90/157], Loss: 293.5907\n",
      "Epoch [1/100], Step [100/157], Loss: 497.7015\n",
      "Epoch [1/100], Step [110/157], Loss: 337.1894\n",
      "Epoch [1/100], Step [120/157], Loss: 302.0459\n",
      "Epoch [1/100], Step [130/157], Loss: 330.5389\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义 YOLOv1 模型\n",
    "model = YOLOv1()  # 自定义的 YOLOv1 模型\n",
    "# 定义计算设备：如果有 GPU 可用，则使用 GPU；否则使用 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = YoloLoss(S=7, B=2, C=20)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.000001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# 开始训练\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)  # 输入图像\n",
    "        targets = targets.to(device)  # 真实标签\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # 前向传播\n",
    "        loss = criterion(outputs, targets)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新模型参数\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Total Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 训练结束\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929462b-2255-4e13-a2f0-5e52c7ff924b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
